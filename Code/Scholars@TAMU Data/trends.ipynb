{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting Trends to Scholars@TAMU  \n",
    "**Filename:** trends.ipynb  \n",
    "**Path:** TAMIDS/Code/Scholars@TAMU Data/trends.ipynb  \n",
    "**Created Date:** 05 April 2022, 01:54 \n",
    "\n",
    "I connect the current trends of various online services to Scholars at Texas A&M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import jieba\n",
    "from gensim import corpora, models, similarities\n",
    "from requests.exceptions import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# General Markdown Formatting Functions\n",
    "\n",
    "def printmd(string, level=1):\n",
    "    header_level = '#'*level + ' '\n",
    "    display(Markdown(header_level + string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gensim_similarities(text_dict: dict, keyword: str) -> dict:\n",
    "    \"\"\"\n",
    "    texts: dict[pub_api_id: text] - bodies of texts to compare against the keyword\n",
    "    keyword: str\n",
    "\n",
    "    returns: dict[key: similarity_num]\n",
    "    \"\"\"\n",
    "\n",
    "    keys, texts = text_dict.keys(), text_dict.values()\n",
    "    cut_texts = [jieba.lcut(text) for text in texts]\n",
    "\n",
    "    dictionary = corpora.Dictionary(cut_texts)\n",
    "    feature_cnt = len(dictionary.token2id)\n",
    "    corpus = [dictionary.doc2bow(text) for text in cut_texts]\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    kw_vector = dictionary.doc2bow(jieba.lcut(keyword))\n",
    "    index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features = feature_cnt)\n",
    "    sim = index[tfidf[kw_vector]]\n",
    "    return {key: val for key, val in zip(keys, sim)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_dict(url: str, kind=None) -> dict:\n",
    "    try:\n",
    "        if kind == 'Wikipedia':\n",
    "            headers = {\n",
    "                'User-Agent': 'My User Agent',\n",
    "                'From': 'abibstopher@tamu.edu'\n",
    "            }\n",
    "            response = requests.get(url, headers=headers)\n",
    "        else:\n",
    "            response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        jsonResponse = response.json()\n",
    "    except HTTPError as http_err:\n",
    "        print(f'HTTP error occurred: {http_err}')\n",
    "    except Exception as err:\n",
    "        print(f'Other error occurred: {err}')\n",
    "    else:\n",
    "        return jsonResponse\n",
    "    return {}\n",
    "\n",
    "def get_wikipedia_article(title: str) -> str:\n",
    "    url = 'https://en.wikipedia.org/wiki/' + title\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    except HTTPError as http_err:\n",
    "        print(f'HTTP error occurred: {http_err}')\n",
    "    except Exception as err:\n",
    "        print(f'Other error occurred: {err}')\n",
    "    else:\n",
    "        text = ''\n",
    "        for paragraph in soup.find_all('p'):\n",
    "            text += paragraph.text\n",
    "            \n",
    "        text = re.sub(r'\\[.*?\\]+', '', text)\n",
    "        text = text.replace('\\n', '')\n",
    "        return text\n",
    "\n",
    "def get_top_wiki_views(access='all-access', date='2022/03/all-days') -> str:\n",
    "    base_url = f'https://wikimedia.org/api/rest_v1/metrics/pageviews/top/en.wikipedia/'\n",
    "    url = base_url + access + '/' + date\n",
    "    return get_api_dict(url=url, kind='Wikipedia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pd.read_pickle('../../Data/Scholars@TAMU/my_api_calls/people_df.pickle')\n",
    "publications = pd.read_pickle('../../Data/Scholars@TAMU/my_api_calls/publications_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pubs abstract sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubs_sample = publications.sample(n=1000, random_state=1)\n",
    "\n",
    "# abstract_dict = {key: pubs_sample['abstract'][key] if type(pubs_sample['abstract'][key]) == str else '' for key in pubs_sample.index.to_list()}\n",
    "abstract_dict = {key: publications['abstract'][key] if type(publications['abstract'][key]) == str else '' for key in publications.index.to_list()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "people\n",
    "\n",
    "keywords_dict = {key: ' '.join(people['keywords'][key]) for key in people.index.to_list()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDE = ['Main_Page', 'Special:Search']\n",
    "\n",
    "top_views = get_top_wiki_views()\n",
    "\n",
    "top_articles = [article for article in top_views['items'][0]['articles']]\n",
    "\n",
    "# wiki_text = get_wikipedia_article(top_articles[2]['article'])\n",
    "\n",
    "[article for article in top_articles]\n",
    "\n",
    "wiki_texts_100 = {article['article']: [get_wikipedia_article(article['article']), article['rank'], article['views']] for article in top_articles[:100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_series = {key: pd.Series(run_gensim_similarities(text_dict=keywords_dict, keyword=value[0])) for key, value in wiki_texts_100.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(similarity_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main_Page</th>\n",
       "      <th>Special:Search</th>\n",
       "      <th>2022_Russian_invasion_of_Ukraine</th>\n",
       "      <th>Vladimir_Putin</th>\n",
       "      <th>The_Batman_(film)</th>\n",
       "      <th>Ukraine</th>\n",
       "      <th>Volodymyr_Zelenskyy</th>\n",
       "      <th>The_Kashmir_Files</th>\n",
       "      <th>Russo-Ukrainian_War</th>\n",
       "      <th>Anna_Sorokin</th>\n",
       "      <th>...</th>\n",
       "      <th>Wagner_Group</th>\n",
       "      <th>F5_Networks</th>\n",
       "      <th>Dune_(2021_film)</th>\n",
       "      <th>Casualties_of_the_Russo-Ukrainian_War</th>\n",
       "      <th>Pieces_of_Her_(TV_series)</th>\n",
       "      <th>Exodus_of_Kashmiri_Hindus</th>\n",
       "      <th>West_Side_Story_(2021_film)</th>\n",
       "      <th>Morbius_(film)</th>\n",
       "      <th>XXX:_State_of_the_Union</th>\n",
       "      <th>XXX_(film_series)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n28cb7333</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n014c3d0f</th>\n",
       "      <td>0.471</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n7a168a93</th>\n",
       "      <td>0.471</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbccd1f64</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n18de9127</th>\n",
       "      <td>0.481</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc1e62471</th>\n",
       "      <td>0.488</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n14b2580b</th>\n",
       "      <td>0.340</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n4f37dfa5</th>\n",
       "      <td>0.177</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n0e788fcb</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nca549702</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4859 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Main_Page  Special:Search  2022_Russian_invasion_of_Ukraine  \\\n",
       "n28cb7333      0.000           0.000                             0.000   \n",
       "n014c3d0f      0.471           0.000                             0.537   \n",
       "n7a168a93      0.471           0.000                             0.538   \n",
       "nbccd1f64      0.315           0.000                             0.359   \n",
       "n18de9127      0.481           0.000                             0.548   \n",
       "...              ...             ...                               ...   \n",
       "nc1e62471      0.488           0.000                             0.555   \n",
       "n14b2580b      0.340           0.000                             0.388   \n",
       "n4f37dfa5      0.177           0.000                             0.202   \n",
       "n0e788fcb      0.000           0.000                             0.000   \n",
       "nca549702      0.000           0.000                             0.000   \n",
       "\n",
       "           Vladimir_Putin  The_Batman_(film)  Ukraine  Volodymyr_Zelenskyy  \\\n",
       "n28cb7333           0.000              0.000    0.000                0.000   \n",
       "n014c3d0f           0.513              0.541    0.483                0.520   \n",
       "n7a168a93           0.513              0.542    0.484                0.521   \n",
       "nbccd1f64           0.343              0.362    0.323                0.348   \n",
       "n18de9127           0.524              0.554    0.494                0.532   \n",
       "...                   ...                ...      ...                  ...   \n",
       "nc1e62471           0.531              0.561    0.500                0.539   \n",
       "n14b2580b           0.372              0.393    0.350                0.378   \n",
       "n4f37dfa5           0.190              0.200    0.180                0.193   \n",
       "n0e788fcb           0.000              0.000    0.000                0.000   \n",
       "nca549702           0.000              0.000    0.000                0.000   \n",
       "\n",
       "           The_Kashmir_Files  Russo-Ukrainian_War  Anna_Sorokin  ...  \\\n",
       "n28cb7333              0.000                0.000         0.000  ...   \n",
       "n014c3d0f              0.501                0.521         0.564  ...   \n",
       "n7a168a93              0.501                0.522         0.564  ...   \n",
       "nbccd1f64              0.335                0.349         0.378  ...   \n",
       "n18de9127              0.512                0.533         0.575  ...   \n",
       "...                      ...                  ...           ...  ...   \n",
       "nc1e62471              0.519                0.540         0.583  ...   \n",
       "n14b2580b              0.364                0.378         0.406  ...   \n",
       "n4f37dfa5              0.184                0.193         0.215  ...   \n",
       "n0e788fcb              0.000                0.000         0.000  ...   \n",
       "nca549702              0.000                0.000         0.000  ...   \n",
       "\n",
       "           Wagner_Group  F5_Networks  Dune_(2021_film)  \\\n",
       "n28cb7333         0.000        0.000             0.000   \n",
       "n014c3d0f         0.507        0.560             0.524   \n",
       "n7a168a93         0.507        0.561             0.525   \n",
       "nbccd1f64         0.339        0.374             0.351   \n",
       "n18de9127         0.518        0.567             0.535   \n",
       "...                 ...          ...               ...   \n",
       "nc1e62471         0.525        0.575             0.543   \n",
       "n14b2580b         0.367        0.394             0.379   \n",
       "n4f37dfa5         0.189        0.228             0.196   \n",
       "n0e788fcb         0.000        0.000             0.000   \n",
       "nca549702         0.000        0.000             0.000   \n",
       "\n",
       "           Casualties_of_the_Russo-Ukrainian_War  Pieces_of_Her_(TV_series)  \\\n",
       "n28cb7333                                  0.000                      0.000   \n",
       "n014c3d0f                                  0.529                      0.535   \n",
       "n7a168a93                                  0.530                      0.536   \n",
       "nbccd1f64                                  0.355                      0.358   \n",
       "n18de9127                                  0.541                      0.546   \n",
       "...                                          ...                        ...   \n",
       "nc1e62471                                  0.547                      0.553   \n",
       "n14b2580b                                  0.382                      0.383   \n",
       "n4f37dfa5                                  0.201                      0.206   \n",
       "n0e788fcb                                  0.000                      0.000   \n",
       "nca549702                                  0.000                      0.000   \n",
       "\n",
       "           Exodus_of_Kashmiri_Hindus  West_Side_Story_(2021_film)  \\\n",
       "n28cb7333                      0.000                        0.000   \n",
       "n014c3d0f                      0.543                        0.501   \n",
       "n7a168a93                      0.544                        0.502   \n",
       "nbccd1f64                      0.363                        0.336   \n",
       "n18de9127                      0.555                        0.512   \n",
       "...                              ...                          ...   \n",
       "nc1e62471                      0.562                        0.519   \n",
       "n14b2580b                      0.394                        0.362   \n",
       "n4f37dfa5                      0.201                        0.189   \n",
       "n0e788fcb                      0.000                        0.000   \n",
       "nca549702                      0.000                        0.000   \n",
       "\n",
       "           Morbius_(film)  XXX:_State_of_the_Union  XXX_(film_series)  \n",
       "n28cb7333           0.000                    0.000              0.000  \n",
       "n014c3d0f           0.530                    0.517              0.535  \n",
       "n7a168a93           0.531                    0.518              0.536  \n",
       "nbccd1f64           0.354                    0.346              0.358  \n",
       "n18de9127           0.542                    0.529              0.548  \n",
       "...                   ...                      ...                ...  \n",
       "nc1e62471           0.549                    0.536              0.556  \n",
       "n14b2580b           0.384                    0.374              0.389  \n",
       "n4f37dfa5           0.198                    0.194              0.196  \n",
       "n0e788fcb           0.000                    0.000              0.000  \n",
       "nca549702           0.000                    0.000              0.000  \n",
       "\n",
       "[4859 rows x 100 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../../Data/Scholars@TAMU/my_api_calls/wikipedia_keyword_comparison.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_text = get_wikipedia_article(top_articles[2]['article'])\n",
    "keyword_similarities = run_gensim_similarities(text_dict=keywords_dict, keyword=wiki_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n032647a0   0.649\n",
      "nbb6c8c2a   0.646\n",
      "n47de353a   0.642\n",
      "n7deb8230   0.639\n",
      "n70a3d026   0.639\n",
      "             ... \n",
      "nd13e4d2d   0.046\n",
      "n2f2205de   0.041\n",
      "n5c077f89   0.033\n",
      "nff831fe5   0.028\n",
      "nfa5c67e9   0.027\n",
      "Length: 3068, dtype: float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "uin                                                        402000618\n",
       "lastname                                                     Carroll\n",
       "middlename                                                         J\n",
       "firstname                                                    Raymond\n",
       "email                                              rcarroll@tamu.edu\n",
       "preferred_title                              Distinguished Professor\n",
       "employment_type                                              Faculty\n",
       "research_areas                                                    []\n",
       "keywords           [2.5 Research Design And Methodologies (aetiol...\n",
       "colleges                                        [College of Science]\n",
       "organizations                                           [Statistics]\n",
       "education          [{'id': 'n032647a0_3482b02b-b399-11e9-adb7-001...\n",
       "teaching           [{'id': 'n62393ae6', 'label': 'STAT485 Directe...\n",
       "publications       [{'id': 'n295784SE', 'label': 'Hierarchical fu...\n",
       "hr_title                                     Distinguished Professor\n",
       "all_positions      [{'id': 'nb0f231e7', 'label': 'Distinguished P...\n",
       "overview                                                            \n",
       "Name: n032647a0, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = pd.Series(keyword_similarities)\n",
    "\n",
    "print(nlp.sort_values(ascending=False)[nlp != 0])\n",
    "\n",
    "people.loc['n032647a0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example DataFrame Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_ids</th>\n",
       "      <th>author_uins</th>\n",
       "      <th>year</th>\n",
       "      <th>publication_type</th>\n",
       "      <th>publication_title</th>\n",
       "      <th>keyword</th>\n",
       "      <th>un_sustainable_development_goals</th>\n",
       "      <th>author_organization</th>\n",
       "      <th>author_city</th>\n",
       "      <th>author_country</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author_names</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publication_api_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n584788SE</th>\n",
       "      <td>[n14bc37c1]</td>\n",
       "      <td>[323009677]</td>\n",
       "      <td>2011</td>\n",
       "      <td>Patent</td>\n",
       "      <td>Scalable traffic classifier and classifier tra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A traffic classifier has a plurality of binary...</td>\n",
       "      <td>[Nicholas Duffield]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n584764SE</th>\n",
       "      <td>[n14bc37c1]</td>\n",
       "      <td>[323009677]</td>\n",
       "      <td>2004</td>\n",
       "      <td>Conference</td>\n",
       "      <td>Flow sampling under hard resource constraints</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[Nicholas Duffield]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n225271SE</th>\n",
       "      <td>[n14bc37c1]</td>\n",
       "      <td>[323009677]</td>\n",
       "      <td>2006</td>\n",
       "      <td>Conference</td>\n",
       "      <td>Sampling Techniques for Large, Dynamic Graphs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[University of Oregon, AT&amp;amp;T Inc.]</td>\n",
       "      <td>[Eugene, San Antonio]</td>\n",
       "      <td>[United States, United States]</td>\n",
       "      <td>Peer-to-peer systems are becoming increasingly...</td>\n",
       "      <td>[Nicholas Duffield]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n584745SE</th>\n",
       "      <td>[n14bc37c1]</td>\n",
       "      <td>[323009677]</td>\n",
       "      <td>2019</td>\n",
       "      <td>Conference</td>\n",
       "      <td>Piecewise Stationary Modeling of Random Proces...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[Nicholas Duffield]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n92767SE</th>\n",
       "      <td>[nbef1f2f3]</td>\n",
       "      <td>[126005180]</td>\n",
       "      <td>2014</td>\n",
       "      <td>Conference</td>\n",
       "      <td>Data curation practices in institutional repos...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Florida State University]</td>\n",
       "      <td>[Tallahassee]</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Dong-Joon Lee]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n367437SE</th>\n",
       "      <td>[nbef1f2f3]</td>\n",
       "      <td>[126005180]</td>\n",
       "      <td>2018</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>Researchers' uses of and disincentives for sha...</td>\n",
       "      <td>[Computer Science, Information Science &amp; Libra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Florida State University, Queens College, Cit...</td>\n",
       "      <td>[Tallahassee, Flushing, College Station]</td>\n",
       "      <td>[United States, United States, United States]</td>\n",
       "      <td>None</td>\n",
       "      <td>[Dong-Joon Lee]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n392518SE</th>\n",
       "      <td>[n731c9f84]</td>\n",
       "      <td>[527006626]</td>\n",
       "      <td>2009</td>\n",
       "      <td>Conference</td>\n",
       "      <td>Multi-label multiple kernel learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Arizona State University, Michigan State Univ...</td>\n",
       "      <td>[Tempe, East Lansing]</td>\n",
       "      <td>[United States, United States]</td>\n",
       "      <td>We present a multi-label multiple kernel learn...</td>\n",
       "      <td>[Shuiwang Ji]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n92775SE</th>\n",
       "      <td>[nbef1f2f3]</td>\n",
       "      <td>[126005180]</td>\n",
       "      <td>2012</td>\n",
       "      <td>Conference</td>\n",
       "      <td>Data determination, disambiguation, and refere...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Florida State University]</td>\n",
       "      <td>[Tallahassee]</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>Entity and instance determination, disambiguat...</td>\n",
       "      <td>[Dong-Joon Lee]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n408107SE</th>\n",
       "      <td>[n3e0f7747, nbef1f2f3, n31ebd4a6, nf489b17d]</td>\n",
       "      <td>[402001311, 126005180, 116006104, 601003827]</td>\n",
       "      <td>2019</td>\n",
       "      <td>Institutional Repository Document (TAMU)</td>\n",
       "      <td>Scholars@TAMU Texas A&amp;M University Librariesâ€™</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas A&amp;M University Libraries has been using ...</td>\n",
       "      <td>[Douglas Hahn, Dong-Joon Lee, Ethelyn Mejia, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n392531SE</th>\n",
       "      <td>[n731c9f84]</td>\n",
       "      <td>[527006626]</td>\n",
       "      <td>2010</td>\n",
       "      <td>Journal Article</td>\n",
       "      <td>A shared-subspace learning framework for multi...</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Arizona State University, Computer-Aided Diag...</td>\n",
       "      <td>[Tempe, Malvern]</td>\n",
       "      <td>[United States, United States]</td>\n",
       "      <td>Multi-label problems arise in various domains ...</td>\n",
       "      <td>[Shuiwang Ji]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      author_ids  \\\n",
       "publication_api_id                                                 \n",
       "n584788SE                                            [n14bc37c1]   \n",
       "n584764SE                                            [n14bc37c1]   \n",
       "n225271SE                                            [n14bc37c1]   \n",
       "n584745SE                                            [n14bc37c1]   \n",
       "n92767SE                                             [nbef1f2f3]   \n",
       "n367437SE                                            [nbef1f2f3]   \n",
       "n392518SE                                            [n731c9f84]   \n",
       "n92775SE                                             [nbef1f2f3]   \n",
       "n408107SE           [n3e0f7747, nbef1f2f3, n31ebd4a6, nf489b17d]   \n",
       "n392531SE                                            [n731c9f84]   \n",
       "\n",
       "                                                     author_uins  year  \\\n",
       "publication_api_id                                                       \n",
       "n584788SE                                            [323009677]  2011   \n",
       "n584764SE                                            [323009677]  2004   \n",
       "n225271SE                                            [323009677]  2006   \n",
       "n584745SE                                            [323009677]  2019   \n",
       "n92767SE                                             [126005180]  2014   \n",
       "n367437SE                                            [126005180]  2018   \n",
       "n392518SE                                            [527006626]  2009   \n",
       "n92775SE                                             [126005180]  2012   \n",
       "n408107SE           [402001311, 126005180, 116006104, 601003827]  2019   \n",
       "n392531SE                                            [527006626]  2010   \n",
       "\n",
       "                                            publication_type  \\\n",
       "publication_api_id                                             \n",
       "n584788SE                                             Patent   \n",
       "n584764SE                                         Conference   \n",
       "n225271SE                                         Conference   \n",
       "n584745SE                                         Conference   \n",
       "n92767SE                                          Conference   \n",
       "n367437SE                                    Journal Article   \n",
       "n392518SE                                         Conference   \n",
       "n92775SE                                          Conference   \n",
       "n408107SE           Institutional Repository Document (TAMU)   \n",
       "n392531SE                                    Journal Article   \n",
       "\n",
       "                                                    publication_title  \\\n",
       "publication_api_id                                                      \n",
       "n584788SE           Scalable traffic classifier and classifier tra...   \n",
       "n584764SE               Flow sampling under hard resource constraints   \n",
       "n225271SE               Sampling Techniques for Large, Dynamic Graphs   \n",
       "n584745SE           Piecewise Stationary Modeling of Random Proces...   \n",
       "n92767SE            Data curation practices in institutional repos...   \n",
       "n367437SE           Researchers' uses of and disincentives for sha...   \n",
       "n392518SE                        Multi-label multiple kernel learning   \n",
       "n92775SE            Data determination, disambiguation, and refere...   \n",
       "n408107SE             Scholars@TAMU Texas A&M University Librariesâ€™   \n",
       "n392531SE           A shared-subspace learning framework for multi...   \n",
       "\n",
       "                                                              keyword  \\\n",
       "publication_api_id                                                      \n",
       "n584788SE                                                         NaN   \n",
       "n584764SE                                                         NaN   \n",
       "n225271SE                                                         NaN   \n",
       "n584745SE                                                         NaN   \n",
       "n92767SE                                                          NaN   \n",
       "n367437SE           [Computer Science, Information Science & Libra...   \n",
       "n392518SE                                                         NaN   \n",
       "n92775SE                                                          NaN   \n",
       "n408107SE                                                         NaN   \n",
       "n392531SE                                          [Computer Science]   \n",
       "\n",
       "                   un_sustainable_development_goals  \\\n",
       "publication_api_id                                    \n",
       "n584788SE                                       NaN   \n",
       "n584764SE                                       NaN   \n",
       "n225271SE                                       NaN   \n",
       "n584745SE                                       NaN   \n",
       "n92767SE                                        NaN   \n",
       "n367437SE                                       NaN   \n",
       "n392518SE                                       NaN   \n",
       "n92775SE                                        NaN   \n",
       "n408107SE                                       NaN   \n",
       "n392531SE                                       NaN   \n",
       "\n",
       "                                                  author_organization  \\\n",
       "publication_api_id                                                      \n",
       "n584788SE                                                         NaN   \n",
       "n584764SE                                                         NaN   \n",
       "n225271SE                       [University of Oregon, AT&amp;T Inc.]   \n",
       "n584745SE                                                         NaN   \n",
       "n92767SE                                   [Florida State University]   \n",
       "n367437SE           [Florida State University, Queens College, Cit...   \n",
       "n392518SE           [Arizona State University, Michigan State Univ...   \n",
       "n92775SE                                   [Florida State University]   \n",
       "n408107SE                                                         NaN   \n",
       "n392531SE           [Arizona State University, Computer-Aided Diag...   \n",
       "\n",
       "                                                 author_city  \\\n",
       "publication_api_id                                             \n",
       "n584788SE                                                NaN   \n",
       "n584764SE                                                NaN   \n",
       "n225271SE                              [Eugene, San Antonio]   \n",
       "n584745SE                                                NaN   \n",
       "n92767SE                                       [Tallahassee]   \n",
       "n367437SE           [Tallahassee, Flushing, College Station]   \n",
       "n392518SE                              [Tempe, East Lansing]   \n",
       "n92775SE                                       [Tallahassee]   \n",
       "n408107SE                                                NaN   \n",
       "n392531SE                                   [Tempe, Malvern]   \n",
       "\n",
       "                                                   author_country  \\\n",
       "publication_api_id                                                  \n",
       "n584788SE                                                     NaN   \n",
       "n584764SE                                                     NaN   \n",
       "n225271SE                          [United States, United States]   \n",
       "n584745SE                                                     NaN   \n",
       "n92767SE                                          [United States]   \n",
       "n367437SE           [United States, United States, United States]   \n",
       "n392518SE                          [United States, United States]   \n",
       "n92775SE                                          [United States]   \n",
       "n408107SE                                                     NaN   \n",
       "n392531SE                          [United States, United States]   \n",
       "\n",
       "                                                             abstract  \\\n",
       "publication_api_id                                                      \n",
       "n584788SE           A traffic classifier has a plurality of binary...   \n",
       "n584764SE                                                        None   \n",
       "n225271SE           Peer-to-peer systems are becoming increasingly...   \n",
       "n584745SE                                                        None   \n",
       "n92767SE                                                         None   \n",
       "n367437SE                                                        None   \n",
       "n392518SE           We present a multi-label multiple kernel learn...   \n",
       "n92775SE            Entity and instance determination, disambiguat...   \n",
       "n408107SE           Texas A&M University Libraries has been using ...   \n",
       "n392531SE           Multi-label problems arise in various domains ...   \n",
       "\n",
       "                                                         author_names  \n",
       "publication_api_id                                                     \n",
       "n584788SE                                         [Nicholas Duffield]  \n",
       "n584764SE                                         [Nicholas Duffield]  \n",
       "n225271SE                                         [Nicholas Duffield]  \n",
       "n584745SE                                         [Nicholas Duffield]  \n",
       "n92767SE                                              [Dong-Joon Lee]  \n",
       "n367437SE                                             [Dong-Joon Lee]  \n",
       "n392518SE                                               [Shuiwang Ji]  \n",
       "n92775SE                                              [Dong-Joon Lee]  \n",
       "n408107SE           [Douglas Hahn, Dong-Joon Lee, Ethelyn Mejia, B...  \n",
       "n392531SE                                               [Shuiwang Ji]  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ['n14bc37c1', 'nf489b17d', 'nc47b6f90', 'n731c9f84', 'nbef1f2f3', 'na9a3fabc', 'n9894eb30']\n",
    "\n",
    "people.loc[ids]\n",
    "\n",
    "def get_author_name(x: object) -> list[str]:\n",
    "    if type(x) == list:\n",
    "        try:\n",
    "            return [f\"{people['firstname'].loc[id]} {people['lastname'].loc[id]}\" for id in x]\n",
    "        except KeyError:\n",
    "            return x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "publications['author_names'] = publications['author_ids'].apply(get_author_name)\n",
    "\n",
    "def find_match(x: object) -> bool:\n",
    "    if type(x) == list:\n",
    "        if (set(x) & set(ids)):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "publications[publications['author_ids'].apply(find_match)].sample(n=10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08d0539260069d16647a15bda43b9d2b76357daee9ecd5899972fb55ddf4875b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('tamids')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
